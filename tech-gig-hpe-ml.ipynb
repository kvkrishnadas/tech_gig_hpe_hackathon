{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Problem statement","metadata":{}},{"cell_type":"markdown","source":"- We are given datasets about different websites\n- The objective of this competition is to identify whether these websites are phishing or not.","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"# Standard libraries\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import KFold\n\n# models\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import BaggingClassifier\n\nfrom sklearn import svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# metrics\nfrom sklearn.metrics import roc_auc_score\n\n# optimizing\nfrom functools import reduce, partial\nfrom scipy.optimize import fmin\n\n# plotting\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:42:14.972737Z","iopub.execute_input":"2022-06-24T08:42:14.973199Z","iopub.status.idle":"2022-06-24T08:42:15.076737Z","shell.execute_reply.started":"2022-06-24T08:42:14.973162Z","shell.execute_reply":"2022-06-24T08:42:15.075729Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tech-gig-hpe/Complete Dataset/Phising_Training_Dataset/Phising_Training_Dataset.csv')\ntest = pd.read_csv('../input/tech-gig-hpe/Complete Dataset/Phising_Testing_Dataset/Phising_Testing_Dataset.csv')\nsample = pd.read_csv('../input/tech-gig-hpe/Complete Dataset/Phising_Sample_Submisson/Phising_Sample_Submisson.csv')\n\ndisplay(train.head())\ndisplay(test.head())\ndisplay(sample.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:23:18.024361Z","iopub.execute_input":"2022-06-24T08:23:18.024759Z","iopub.status.idle":"2022-06-24T08:23:18.104283Z","shell.execute_reply.started":"2022-06-24T08:23:18.024727Z","shell.execute_reply":"2022-06-24T08:23:18.103176Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"- Result is the target column. -1 stands for a phishing website and 1 for non-phishing website","metadata":{}},{"cell_type":"code","source":"train.isnull().sum(), test.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:32:35.058862Z","iopub.status.idle":"2022-06-24T08:32:35.059322Z","shell.execute_reply.started":"2022-06-24T08:32:35.059118Z","shell.execute_reply":"2022-06-24T08:32:35.059138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- No null values","metadata":{}},{"cell_type":"code","source":"train.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:40:49.465515Z","iopub.execute_input":"2022-06-24T08:40:49.467076Z","iopub.status.idle":"2022-06-24T08:40:49.479115Z","shell.execute_reply.started":"2022-06-24T08:40:49.467026Z","shell.execute_reply":"2022-06-24T08:40:49.477455Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"- All features are of integer datatype. So no encoding needed.","metadata":{}},{"cell_type":"markdown","source":"## Distribution of train and test features","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=5, ncols=4, figsize=(20, 20))  # define the figure and subplots\naxes = axes.ravel() \nfeatures = set(test.columns.to_list()) - set(['key'])\n\n\nfor column, ax in zip(features, axes):\n    distribution = pd.concat([train[column].value_counts(normalize = True), test[column].value_counts(normalize = True)],\n                      axis = 1, join = 'inner', keys = ['train', 'test'])\n    distribution.plot.bar(ax = ax, title = column)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:43:07.354770Z","iopub.execute_input":"2022-06-24T08:43:07.355212Z","iopub.status.idle":"2022-06-24T08:43:10.244688Z","shell.execute_reply.started":"2022-06-24T08:43:07.355178Z","shell.execute_reply":"2022-06-24T08:43:10.241862Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"- Train and test datasets have similar distributions","metadata":{}},{"cell_type":"code","source":"kfold = KFold(n_splits=10, shuffle=True, random_state=13)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:23:18.106097Z","iopub.execute_input":"2022-06-24T08:23:18.106426Z","iopub.status.idle":"2022-06-24T08:23:18.111689Z","shell.execute_reply.started":"2022-06-24T08:23:18.106397Z","shell.execute_reply":"2022-06-24T08:23:18.110583Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"y = train.Result\ndf_1 = train.copy()\nfor fold, (t, v) in enumerate(kfold.split(X = df_1, y = y)):\n    df_1.loc[v, 'k_fold'] = fold","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:23:18.164172Z","iopub.execute_input":"2022-06-24T08:23:18.164756Z","iopub.status.idle":"2022-06-24T08:23:18.181740Z","shell.execute_reply.started":"2022-06-24T08:23:18.164723Z","shell.execute_reply":"2022-06-24T08:23:18.180751Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier( n_jobs = -1)\n\nsvc = svm.SVC(random_state = 5,\n             probability = True)\nlr = LogisticRegression(max_iter = 200, random_state = 7, n_jobs = -1)\n\n\nxgb = XGBClassifier(n_jobs = -1,\n#                     tree_method = 'gpu_hist',\n                    use_label_encoder=False, eval_metric='logloss', random_state = 8)\n\nlgbm = LGBMClassifier(\n#     device='gpu',\n    n_jobs = -1, random_state = 9)\n\n \ncat = CatBoostClassifier( verbose=0, \n#                          task_type='GPU',\n                        random_state = 3)\n\nbc_dt = BaggingClassifier(n_jobs = -1, random_state = 4)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:23:18.244633Z","iopub.execute_input":"2022-06-24T08:23:18.247131Z","iopub.status.idle":"2022-06-24T08:23:18.261189Z","shell.execute_reply.started":"2022-06-24T08:23:18.247085Z","shell.execute_reply":"2022-06-24T08:23:18.260053Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"features = test.columns.to_list()\ndf_1.Result.replace({-1:0}, inplace = True)\ny = df_1.Result\ndef run_training(fold, model, model_name, df = df_1):\n    \"\"\" prints scores for each folds and returns keys and predictions for each model\"\"\"\n    \n    df_train = df[df.k_fold != fold].reset_index(drop = True)\n    df_valid = df[df.k_fold == fold].reset_index(drop = True)\n    \n    X_train = df_train[features]\n    X_valid = df_valid[features]\n    \n    y_train = df_train.Result\n    y_valid = df_valid.Result\n    \n    model.fit(X_train, y_train)\n    predictions = model.predict_proba(X_valid)[:, 1]\n    score = roc_auc_score(y_valid, predictions)\n    \n    print(f'fold = {fold}, roc_auc_score = {score}')\n    \n    df_valid.loc[:, f'{model_name}_pred'] = predictions\n    \n    return df_valid[['key', f'{model_name}_pred']]","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:23:18.284294Z","iopub.execute_input":"2022-06-24T08:23:18.284710Z","iopub.status.idle":"2022-06-24T08:23:18.295127Z","shell.execute_reply.started":"2022-06-24T08:23:18.284676Z","shell.execute_reply":"2022-06-24T08:23:18.294294Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regression","metadata":{}},{"cell_type":"code","source":"dfs = []\nfor fold in range(10):\n    temp_df = run_training(fold, lr, 'lr')\n    dfs.append(temp_df)\n    \nlr_valid_df = pd.concat(dfs)\nprint(lr_valid_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:23:18.314003Z","iopub.execute_input":"2022-06-24T08:23:18.314975Z","iopub.status.idle":"2022-06-24T08:23:26.442303Z","shell.execute_reply.started":"2022-06-24T08:23:18.314938Z","shell.execute_reply":"2022-06-24T08:23:26.438865Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## CatBoost Classifier","metadata":{}},{"cell_type":"code","source":"dfs = []\nfor fold in range(10):\n    temp_df = run_training(fold, cat, 'cat')\n    dfs.append(temp_df)\n    \ncat_valid_df = pd.concat(dfs)\nprint(cat_valid_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:23:26.450243Z","iopub.execute_input":"2022-06-24T08:23:26.451292Z","iopub.status.idle":"2022-06-24T08:24:03.372812Z","shell.execute_reply.started":"2022-06-24T08:23:26.451228Z","shell.execute_reply":"2022-06-24T08:24:03.371652Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Support Vector Classifier","metadata":{}},{"cell_type":"code","source":"dfs = []\nfor fold in range(10):\n    temp_df = run_training(fold, svc, 'svc')\n    dfs.append(temp_df)\n    \nsvc_valid_df = pd.concat(dfs)\nprint(svc_valid_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:24:03.374647Z","iopub.execute_input":"2022-06-24T08:24:03.375133Z","iopub.status.idle":"2022-06-24T08:28:24.043485Z","shell.execute_reply.started":"2022-06-24T08:24:03.375088Z","shell.execute_reply":"2022-06-24T08:28:24.042191Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## K Nearest Neighbours Classifier","metadata":{}},{"cell_type":"code","source":"dfs = []\nfor fold in range(10):\n    temp_df = run_training(fold, knn, 'knn')\n    dfs.append(temp_df)\n    \nknn_valid_df = pd.concat(dfs)\nprint(knn_valid_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:28:24.046585Z","iopub.execute_input":"2022-06-24T08:28:24.047059Z","iopub.status.idle":"2022-06-24T08:28:26.696477Z","shell.execute_reply.started":"2022-06-24T08:28:24.047013Z","shell.execute_reply":"2022-06-24T08:28:26.695258Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Light Gradient Boost Classifier","metadata":{}},{"cell_type":"code","source":"dfs = []\nfor fold in range(10):\n    temp_df = run_training(fold, lgbm, 'lgbm')\n    dfs.append(temp_df)\n    \nlgbm_valid_df = pd.concat(dfs)\nprint(lgbm_valid_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:28:26.698413Z","iopub.execute_input":"2022-06-24T08:28:26.698895Z","iopub.status.idle":"2022-06-24T08:28:29.481926Z","shell.execute_reply.started":"2022-06-24T08:28:26.698832Z","shell.execute_reply":"2022-06-24T08:28:29.480962Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## eXtreame Gradient Boost Classifier","metadata":{}},{"cell_type":"code","source":"dfs = []\nfor fold in range(10):\n    temp_df = run_training(fold, xgb, 'xgb')\n    dfs.append(temp_df)\n    \nxgb_valid_df = pd.concat(dfs)\nprint(xgb_valid_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:28:29.483424Z","iopub.execute_input":"2022-06-24T08:28:29.483855Z","iopub.status.idle":"2022-06-24T08:28:40.591991Z","shell.execute_reply.started":"2022-06-24T08:28:29.483814Z","shell.execute_reply":"2022-06-24T08:28:40.591018Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Bagging Classifier with decision tree as base estimator","metadata":{}},{"cell_type":"code","source":"dfs = []\nfor fold in range(10):\n    temp_df = run_training(fold, bc_dt, 'bc_dt')\n    dfs.append(temp_df)\n    \nbc_dt_valid_df = pd.concat(dfs)\nprint(bc_dt_valid_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:28:40.596987Z","iopub.execute_input":"2022-06-24T08:28:40.598068Z","iopub.status.idle":"2022-06-24T08:28:43.863179Z","shell.execute_reply.started":"2022-06-24T08:28:40.598015Z","shell.execute_reply":"2022-06-24T08:28:43.861786Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# combining all predictions to a dataframe\nfinal_df        = [cat_valid_df, lr_valid_df, lgbm_valid_df, xgb_valid_df,\n                    bc_dt_valid_df, df_1[['key', 'k_fold', 'Result']]]\nfinal_pred        = reduce(lambda left,right: pd.merge(left,right,on='key'), final_df)\nfinal_pred.sort_values(by = 'key', inplace = True)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:38:09.126550Z","iopub.execute_input":"2022-06-24T08:38:09.127170Z","iopub.status.idle":"2022-06-24T08:38:09.157422Z","shell.execute_reply.started":"2022-06-24T08:38:09.127126Z","shell.execute_reply":"2022-06-24T08:38:09.156475Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"pred_cols = ['cat_pred', 'lr_pred', 'lgbm_pred', 'xgb_pred', 'bc_dt_pred']\nfor col in pred_cols:\n    score = roc_auc_score(y, final_pred[col])\n    print(f'{col}, overall_auc = {score}')","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:38:10.153007Z","iopub.execute_input":"2022-06-24T08:38:10.153896Z","iopub.status.idle":"2022-06-24T08:38:10.188717Z","shell.execute_reply.started":"2022-06-24T08:38:10.153827Z","shell.execute_reply":"2022-06-24T08:38:10.187481Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"- Lowest perfoming models svc and knn are removed","metadata":{}},{"cell_type":"markdown","source":"- CatBoost is the highest perfoming model","metadata":{}},{"cell_type":"markdown","source":"# Blending","metadata":{}},{"cell_type":"code","source":"print('avg_pred')\nroc_auc_score(y, np.mean(final_pred[pred_cols], axis = 1))","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:38:31.295600Z","iopub.execute_input":"2022-06-24T08:38:31.296651Z","iopub.status.idle":"2022-06-24T08:38:31.314719Z","shell.execute_reply.started":"2022-06-24T08:38:31.296610Z","shell.execute_reply":"2022-06-24T08:38:31.313493Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"lr_ranks = final_pred.lr_pred.rank()\ncat_ranks = final_pred.cat_pred.rank()\nlgbm_ranks = final_pred.lgbm_pred.rank()\nxgb_ranks = final_pred.xgb_pred.rank()\n\navg_rank = (lr_ranks + cat_ranks + lgbm_ranks + xgb_ranks) / 4\n\nprint('avg_rank')\nroc_auc_score(y, avg_rank)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:38:32.764639Z","iopub.execute_input":"2022-06-24T08:38:32.765099Z","iopub.status.idle":"2022-06-24T08:38:32.787972Z","shell.execute_reply.started":"2022-06-24T08:38:32.765061Z","shell.execute_reply":"2022-06-24T08:38:32.786797Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# Optimizing roc_auc","metadata":{}},{"cell_type":"code","source":"class optimize_auc():\n    \n    def __init__(self):\n        self.coef_ = 0\n        \n    def auc(self, coef, X, y):\n        X_coef = X * coef                             # multiplying with coefficient\n        predictions = np.sum(X_coef, axis = 1)\n        auc_score = roc_auc_score(y, predictions)\n        return -1.0 * auc_score                       # multiplying with -1 because we are using fmin\n    \n    def fit(self, X, y):\n        partial_loss = partial(self.auc, X = X, y = y)\n        init_coef = np.random.dirichlet(np.ones(X.shape[1]))\n        self.coef_ = fmin(partial_loss, init_coef, disp = True)\n        \n    def predict(self, X):\n        X_coef = X *  self.coef_\n        predictions = np.sum(X_coef, axis = 1)\n        return predictions\n    \n\n\ndef run_training_final(pred_df, fold):\n    df_train = pred_df[pred_df.k_fold != fold].reset_index(drop = True)\n    df_valid = pred_df[pred_df.k_fold == fold].reset_index(drop = True)\n    \n    X_train = df_train[pred_cols]\n    X_valid = df_valid[pred_cols]\n    \n    opt = optimize_auc()\n    opt.fit(X_train, df_train.Result)\n    predictions = opt.predict(X_valid)\n    auc = roc_auc_score(df_valid.Result, predictions)\n    print(f'{fold}, {auc}')\n    df_valid.loc[:, 'opt_pred'] = predictions\n    return opt.coef_ \n\ncoefs = []\nfor fold in range(10):\n    coefs.append(run_training_final(final_pred, fold))\n    \ncoefs = np.array(coefs)\n\ncoefs = np.mean(coefs, axis = 0)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:38:36.574746Z","iopub.execute_input":"2022-06-24T08:38:36.575747Z","iopub.status.idle":"2022-06-24T08:38:48.578226Z","shell.execute_reply.started":"2022-06-24T08:38:36.575707Z","shell.execute_reply":"2022-06-24T08:38:48.576916Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"wt_avg = coefs[0] * final_pred.cat_pred + coefs[1] * final_pred.lr_pred + coefs[2] * final_pred.lgbm_pred + coefs[3] * final_pred.xgb_pred +  coefs[4] * final_pred.bc_dt_pred\nroc_auc_score(y, wt_avg) ","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:39:55.995445Z","iopub.execute_input":"2022-06-24T08:39:55.995961Z","iopub.status.idle":"2022-06-24T08:39:56.013946Z","shell.execute_reply.started":"2022-06-24T08:39:55.995920Z","shell.execute_reply":"2022-06-24T08:39:56.012309Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"- By blending and optimising weights of each models, roc_auc_score is improved","metadata":{}}]}